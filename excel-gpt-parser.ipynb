{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 12:52:26,527 [ERROR] Task exception was never retrieved\n",
      "future: <Task finished name='Task-132' coro=<Server.serve() done, defined at c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\server.py:69> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\main.py\", line 580, in run\n",
      "    server.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\server.py\", line 67, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\che98\\AppData\\Roaming\\Python\\Python313\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\Users\\che98\\AppData\\Roaming\\Python\\Python313\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\che98\\AppData\\Roaming\\Python\\Python313\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "    ~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py\", line 386, in __wakeup\n",
      "    self.__step()\n",
      "    ~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py\", line 293, in __step\n",
      "    self.__step_run_and_handle_result(exc)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\server.py\", line 70, in serve\n",
      "    with self.capture_signals():\n",
      "         ~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 148, in __exit__\n",
      "    next(self.gen)\n",
      "    ~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\server.py\", line 331, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "INFO:     Started server process [34748]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:54595 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54595 - \"GET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:54595 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 12:53:04,780 [INFO] 업로드됨: uploaded\\2025 3차 채권매각명세.xlsx\n",
      "2025-07-24 12:53:35,423 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-24 12:53:37,808 [ERROR] Task exception was never retrieved\n",
      "future: <Task finished name='Task-123' coro=<Server.serve() done, defined at c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\server.py:69> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\main.py\", line 580, in run\n",
      "    server.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\server.py\", line 67, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\che98\\AppData\\Roaming\\Python\\Python313\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\Users\\che98\\AppData\\Roaming\\Python\\Python313\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\che98\\AppData\\Roaming\\Python\\Python313\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "    ~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py\", line 386, in __wakeup\n",
      "    self.__step()\n",
      "    ~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py\", line 293, in __step\n",
      "    self.__step_run_and_handle_result(exc)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\server.py\", line 70, in serve\n",
      "    with self.capture_signals():\n",
      "         ~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 148, in __exit__\n",
      "    next(self.gen)\n",
      "    ~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\che98\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\server.py\", line 331, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "2025-07-24 12:55:03,664 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-24 12:56:37,733 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-24 12:58:13,116 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-24 12:59:45,491 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-24 13:01:27,658 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:54596 - \"POST /upload/ HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, json, logging, re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import FileResponse\n",
    "from openpyxl import load_workbook\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio, uvicorn\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# 환경 설정\n",
    "# ───────────────────────────────────────────\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TEMPLATE_PATH = Path(os.getenv(\"TEMPLATE_PATH\", r\"C:\\Users\\che98\\Downloads\\수익률표(Brief Version)_1.0_템플릿.xlsx\"))\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# FastAPI 앱 및 로깅 설정\n",
    "# ───────────────────────────────────────────\n",
    "app = FastAPI()\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "log = logging.getLogger(__name__)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# 유틸 함수\n",
    "# ───────────────────────────────────────────\n",
    "def find_last_row(ws):\n",
    "    for row in reversed(range(1, ws.max_row + 1)):\n",
    "        if any(cell.value for cell in ws[row]):\n",
    "            return row\n",
    "    return 2\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# GPT 호출 - 첫 배치\n",
    "# ───────────────────────────────────────────\n",
    "def call_gpt_first_batch(batch_text: str, batch_idx: int) -> tuple[List[dict], List[str]]:\n",
    "    prompt = f\"\"\"\n",
    "다음은 부실채권 요약 텍스트 목록입니다. \n",
    "\n",
    "**1단계: 헤더 정보 추출**\n",
    "먼저 이 데이터에서 컬럼 헤더나 필드명을 찾아서 리스트로 추출해주세요.\n",
    "\n",
    "**2단계: 데이터 정리**\n",
    "각 항목을 아래 항목들에 맞게 JSON으로 정리해주세요:\n",
    "\n",
    "- 숫자는 쉼표(,) 없이 숫자형으로, 소수점은 유지해주세요\n",
    "- 이자율은 소수점 값으로 출력해주세요 (예: 12.5, 3.75 등)\n",
    "- 같은 필드가 한 줄에 여러 번 등장하면 합산\n",
    "- 항목이 중복되면 적절히 구분해서 필드에 배정\n",
    "- 특히, 가지급금은 \"여신성 가지급금\"으로, 미수이자는 \"이자금액\" 또는 \"채권 권리 합계\"와 구분\n",
    "- 채권최고액은 보통 가장 큰 금액이며 그 항목 전용으로\n",
    "\n",
    "필드: 주소, 호수, 검토일, 차주, 반장님 전달, 매각여부, 경매/공매, 담당기관, 물건종류, 세대수, 대지면적, 전용면적(합계), 대출잔액, 이자금액, 연체이자율, 대출원금, 채권 권리 합계, 채권최고액, 감정가, 선순위 합계, 여신성 가지급금\n",
    "\n",
    "입력:\n",
    "{batch_text}\n",
    "\n",
    "응답 형식:\n",
    "```json\n",
    "{{\n",
    "  \"headers\": [\"감지된 헤더1\", \"감지된 헤더2\", ...],\n",
    "  \"data\": [\n",
    "    {{\"주소\": \"값\", \"호수\": \"값\", ...}},\n",
    "    {{\"주소\": \"값\", \"호수\": \"값\", ...}}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\"\"\"\n",
    "    with open(f\"prompt_batch_{batch_idx+1}_first.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(prompt)\n",
    "\n",
    "    try:\n",
    "        res = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        msg = res.choices[0].message.content.strip()\n",
    "        match = re.search(r\"```json\\s*(.*?)```\", msg, re.DOTALL)\n",
    "        json_str = match.group(1).strip() if match else msg\n",
    "        result = json.loads(json_str)\n",
    "        return result.get(\"data\", []), result.get(\"headers\", [])\n",
    "    except Exception as e:\n",
    "        with open(f\"gpt_error_batch_{batch_idx+1}_first.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(msg if 'msg' in locals() else str(e))\n",
    "        raise RuntimeError(f\"GPT 응답 파싱 실패: {e}\")\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# GPT 호출 - 이후 배치\n",
    "# ───────────────────────────────────────────\n",
    "def call_gpt_with_headers(batch_text: str, batch_idx: int, headers: List[str]) -> List[dict]:\n",
    "    headers_str = \", \".join(headers) if headers else \"헤더 정보 없음\"\n",
    "    prompt = f\"\"\"\n",
    "다음은 부실채권 요약 텍스트 목록입니다. \n",
    "\n",
    "**참고 헤더 정보:**\n",
    "이전 배치에서 감지된 헤더: {headers_str}\n",
    "\n",
    "이 헤더 정보를 참고하여 각 항목을 아래 항목들에 맞게 JSON으로 정리해주세요:\n",
    "\n",
    "- 숫자는 쉼표(,) 없이 숫자형으로, 소수점은 유지해주세요\n",
    "- 이자율은 소수점 값으로 출력해주세요 (예: 12.5, 3.75 등)\n",
    "- 같은 필드가 한 줄에 여러 번 등장하면 합산\n",
    "- 항목이 중복되면 적절히 구분해서 필드에 배정\n",
    "- 특히, 가지급금은 \"여신성 가지급금\"으로, 미수이자는 \"이자금액\" 또는 \"채권 권리 합계\"와 구분\n",
    "- 채권최고액은 보통 가장 큰 금액이며 그 항목 전용으로\n",
    "- 출력은 반드시 ```json 으로 감싸진 JSON 리스트로\n",
    "\n",
    "필드: 주소, 호수, 검토일, 차주, 반장님 전달, 매각여부, 경매/공매, 담당기관, 물건종류, 세대수, 대지면적, 전용면적(합계), 대출잔액, 이자금액, 연체이자율, 대출원금, 채권 권리 합계, 채권최고액, 감정가, 선순위 합계, 여신성 가지급금\n",
    "\n",
    "입력:\n",
    "{batch_text}\n",
    "\n",
    "응답 형식은 반드시 ```json 블록으로 시작해서 JSON 리스트만 포함해주세요.\n",
    "\"\"\"\n",
    "\n",
    "    with open(f\"prompt_batch_{batch_idx+1}_with_headers.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(prompt)\n",
    "\n",
    "    try:\n",
    "        res = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        msg = res.choices[0].message.content.strip()\n",
    "        match = re.search(r\"```json\\s*(.*?)```\", msg, re.DOTALL)\n",
    "        json_str = match.group(1).strip() if match else msg\n",
    "        return json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        with open(f\"gpt_error_batch_{batch_idx+1}_with_headers.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(msg if 'msg' in locals() else str(e))\n",
    "        raise RuntimeError(f\"GPT 응답 파싱 실패: {e}\")\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# Excel 데이터 추출 및 분할\n",
    "# ───────────────────────────────────────────\n",
    "def extract_batches_from_excel(file_path: str, batch_size: int = 10) -> List[List[str]]:\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    all_rows = []\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name, dtype=str, header=1).fillna(\"\")\n",
    "            for _, row in df.iterrows():\n",
    "                text = f\"[{sheet_name}] \" + \" | \".join([f\"{col}:{row[col]}\" for col in df.columns])\n",
    "                all_rows.append(text)\n",
    "        except Exception as e:\n",
    "            log.warning(f\"⚠️ 시트 '{sheet_name}' 처리 실패: {e}\")\n",
    "    return [all_rows[i:i+batch_size] for i in range(0, len(all_rows), batch_size)]\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# Excel 결과 삽입\n",
    "# ───────────────────────────────────────────\n",
    "def insert_batch_to_excel(batch_data: List[dict], output_path: str):\n",
    "    wb = load_workbook(output_path)\n",
    "    ws = wb[\"List\"]\n",
    "    col_order = [cell.value for cell in ws[2] if cell.value]\n",
    "    start_col = 2\n",
    "    start_row = find_last_row(ws) + 1\n",
    "    money_fields = [\n",
    "        \"감정가\", \"대출잔액\", \"이자금액\", \"대출원금\", \"채권 권리 합계\",\n",
    "        \"채권최고액\", \"선순위 합계\", \"여신성 가지급금\"\n",
    "    ]\n",
    "\n",
    "    for item in batch_data:\n",
    "        for col_idx, col_name in enumerate(col_order):\n",
    "            raw = item.get(col_name, \"\")\n",
    "            if col_name in money_fields:\n",
    "                try:\n",
    "                    value = float(re.sub(r\"[^\\d]\", \"\", str(raw))) if re.search(r\"\\d\", str(raw)) else None\n",
    "                except:\n",
    "                    value = None\n",
    "            else:\n",
    "                value = raw\n",
    "            ws.cell(row=start_row, column=start_col + col_idx, value=value)\n",
    "        start_row += 1\n",
    "\n",
    "    wb.save(output_path)\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# 전체 프로세스 실행\n",
    "# ───────────────────────────────────────────\n",
    "def process_file(upload_path: str, output_path: str):\n",
    "    batches = extract_batches_from_excel(upload_path)\n",
    "    detected_headers = []\n",
    "    \n",
    "    for idx, batch in enumerate(batches):\n",
    "        try:\n",
    "            batch_text = \"\\n\\n\".join(batch)\n",
    "            if idx == 0:\n",
    "                data, headers = call_gpt_first_batch(batch_text, idx)\n",
    "                detected_headers = headers\n",
    "                with open(\"detected_headers.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(detected_headers, f, ensure_ascii=False, indent=2)\n",
    "            else:\n",
    "                data = call_gpt_with_headers(batch_text, idx, detected_headers)\n",
    "            insert_batch_to_excel(data, output_path)\n",
    "        except Exception as e:\n",
    "            log.error(f\"❌ 배치 {idx+1} 실패: {e}\")\n",
    "            continue\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# 업로드 엔드포인트\n",
    "# ───────────────────────────────────────────\n",
    "@app.post(\"/upload/\")\n",
    "async def upload_and_process(file: UploadFile = File(...)):\n",
    "    upload_dir = Path(\"uploaded\")\n",
    "    upload_dir.mkdir(exist_ok=True)\n",
    "    file_path = upload_dir / file.filename\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        shutil.copyfileobj(file.file, f)\n",
    "    log.info(f\"업로드됨: {file_path}\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out = Path(f\"작성본_{Path(file.filename).stem}_{timestamp}.xlsx\")\n",
    "    shutil.copyfile(TEMPLATE_PATH, out)\n",
    "\n",
    "    try:\n",
    "        process_file(str(file_path), str(out))\n",
    "    except Exception as e:\n",
    "        log.error(\"처리 실패\", exc_info=e)\n",
    "        raise HTTPException(status_code=500, detail=f\"처리 실패: {e}\")\n",
    "\n",
    "    return FileResponse(out)\n",
    "\n",
    "# ───────────────────────────────────────────\n",
    "# 로컬 실행\n",
    "# ───────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
