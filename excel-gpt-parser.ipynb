import os, shutil, json, logging, re
import pandas as pd
from pathlib import Path
from typing import List
from datetime import datetime
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import FileResponse
from openpyxl import load_workbook
from openai import OpenAI
from dotenv import load_dotenv
import nest_asyncio, uvicorn

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TEMPLATE_PATH = Path(os.getenv("TEMPLATE_PATH", r"C:\Users\che98\Downloads\ìˆ˜ìµë¥ í‘œ(Brief Version)_1.0_í…œí”Œë¦¿.xlsx"))
client = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FastAPI ì•± ë° ë¡œê¹… ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
log = logging.getLogger(__name__)
nest_asyncio.apply()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_last_row(ws):
    for row in reversed(range(1, ws.max_row + 1)):
        if any(cell.value for cell in ws[row]):
            return row
    return 2

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GPT í˜¸ì¶œ - ì²« ë°°ì¹˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_gpt_first_batch(batch_text: str, batch_idx: int) -> tuple[List[dict], List[str]]:
    prompt = f"""
ë‹¤ìŒì€ ë¶€ì‹¤ì±„ê¶Œ ìš”ì•½ í…ìŠ¤íŠ¸ ëª©ë¡ì…ë‹ˆë‹¤. 

**1ë‹¨ê³„: í—¤ë” ì •ë³´ ì¶”ì¶œ**
ë¨¼ì € ì´ ë°ì´í„°ì—ì„œ ì»¬ëŸ¼ í—¤ë”ë‚˜ í•„ë“œëª…ì„ ì°¾ì•„ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**2ë‹¨ê³„: ë°ì´í„° ì •ë¦¬**
ê° í•­ëª©ì„ ì•„ë˜ í•­ëª©ë“¤ì— ë§ê²Œ JSONìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

- ìˆ«ìëŠ” ì‰¼í‘œ(,) ì—†ì´ ìˆ«ìí˜•ìœ¼ë¡œ, ì†Œìˆ˜ì ì€ ìœ ì§€í•´ì£¼ì„¸ìš”
- **ì´ììœ¨ì€ %ë¥¼ ì œê±°í•˜ê³  ì†Œìˆ˜ì  í˜•íƒœë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”** (ì˜ˆ: 11.323%ì´ë©´ 0.11323ìœ¼ë¡œ)
- ê°™ì€ í•„ë“œê°€ í•œ ì¤„ì— ì—¬ëŸ¬ ë²ˆ ë“±ì¥í•˜ë©´ í•©ì‚°
- í•­ëª©ì´ ì¤‘ë³µë˜ë©´ ì ì ˆíˆ êµ¬ë¶„í•´ì„œ í•„ë“œì— ë°°ì •
- íŠ¹íˆ, ê°€ì§€ê¸‰ê¸ˆì€ "ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ"ìœ¼ë¡œ, ë¯¸ìˆ˜ì´ìëŠ” "ì´ìê¸ˆì•¡" ë˜ëŠ” "ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„"ì™€ êµ¬ë¶„
- ì±„ê¶Œìµœê³ ì•¡ì€ ë³´í†µ ê°€ì¥ í° ê¸ˆì•¡ì´ë©° ê·¸ í•­ëª© ì „ìš©ìœ¼ë¡œ

í•„ë“œ: ì£¼ì†Œ, í˜¸ìˆ˜, ê²€í† ì¼, ì°¨ì£¼, ë°˜ì¥ë‹˜ ì „ë‹¬, ë§¤ê°ì—¬ë¶€, ê²½ë§¤/ê³µë§¤, ë‹´ë‹¹ê¸°ê´€, ë¬¼ê±´ì¢…ë¥˜, ì„¸ëŒ€ìˆ˜, ëŒ€ì§€ë©´ì , ì „ìš©ë©´ì (í•©ê³„), ëŒ€ì¶œì”ì•¡, ì´ìê¸ˆì•¡, ì—°ì²´ì´ììœ¨, ëŒ€ì¶œì›ê¸ˆ, ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„, ì±„ê¶Œìµœê³ ì•¡, ê°ì •ê°€, ì„ ìˆœìœ„ í•©ê³„, ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ

ì…ë ¥:
{batch_text}

ì‘ë‹µ í˜•ì‹:
```json
{{
  "headers": ["ê°ì§€ëœ í—¤ë”1", "ê°ì§€ëœ í—¤ë”2", ...],
  "data": [
    {{"ì£¼ì†Œ": "ê°’", "í˜¸ìˆ˜": "ê°’", ...}},
    {{"ì£¼ì†Œ": "ê°’", "í˜¸ìˆ˜": "ê°’", ...}}
  ]
}}
```
"""
    with open(f"prompt_batch_{batch_idx+1}_first.txt", "w", encoding="utf-8") as f:
        f.write(prompt)

    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            max_tokens=4096
        )
        msg = res.choices[0].message.content.strip()
        match = re.search(r"```json\s*(.*?)```", msg, re.DOTALL)
        json_str = match.group(1).strip() if match else msg
        result = json.loads(json_str)
        return result.get("data", []), result.get("headers", [])
    except Exception as e:
        with open(f"gpt_error_batch_{batch_idx+1}_first.txt", "w", encoding="utf-8") as f:
            f.write(msg if 'msg' in locals() else str(e))
        raise RuntimeError(f"GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GPT í˜¸ì¶œ - ì´í›„ ë°°ì¹˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_gpt_with_headers(batch_text: str, batch_idx: int, headers: List[str]) -> List[dict]:
    headers_str = ", ".join(headers) if headers else "í—¤ë” ì •ë³´ ì—†ìŒ"
    prompt = f"""
ë‹¤ìŒì€ ë¶€ì‹¤ì±„ê¶Œ ìš”ì•½ í…ìŠ¤íŠ¸ ëª©ë¡ì…ë‹ˆë‹¤. 

**ì°¸ê³  í—¤ë” ì •ë³´:**
ì´ì „ ë°°ì¹˜ì—ì„œ ê°ì§€ëœ í—¤ë”: {headers_str}

ì´ í—¤ë” ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ê° í•­ëª©ì„ ì•„ë˜ í•­ëª©ë“¤ì— ë§ê²Œ JSONìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

- ìˆ«ìëŠ” ì‰¼í‘œ(,) ì—†ì´ ìˆ«ìí˜•ìœ¼ë¡œ, ì†Œìˆ˜ì ì€ ìœ ì§€í•´ì£¼ì„¸ìš”
- **ì´ììœ¨ì€ %ë¥¼ ì œê±°í•˜ê³  ì†Œìˆ˜ì  í˜•íƒœë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”** (ì˜ˆ: 11.323%ì´ë©´ 0.11323ìœ¼ë¡œ)
- ê°™ì€ í•„ë“œê°€ í•œ ì¤„ì— ì—¬ëŸ¬ ë²ˆ ë“±ì¥í•˜ë©´ í•©ì‚°
- í•­ëª©ì´ ì¤‘ë³µë˜ë©´ ì ì ˆíˆ êµ¬ë¶„í•´ì„œ í•„ë“œì— ë°°ì •
- íŠ¹íˆ, ê°€ì§€ê¸‰ê¸ˆì€ "ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ"ìœ¼ë¡œ, ë¯¸ìˆ˜ì´ìëŠ” "ì´ìê¸ˆì•¡" ë˜ëŠ” "ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„"ì™€ êµ¬ë¶„
- ì±„ê¶Œìµœê³ ì•¡ì€ ë³´í†µ ê°€ì¥ í° ê¸ˆì•¡ì´ë©° ê·¸ í•­ëª© ì „ìš©ìœ¼ë¡œ
- ì¶œë ¥ì€ ë°˜ë“œì‹œ ```json ìœ¼ë¡œ ê°ì‹¸ì§„ JSON ë¦¬ìŠ¤íŠ¸ë¡œ

í•„ë“œ: ì£¼ì†Œ, í˜¸ìˆ˜, ê²€í† ì¼, ì°¨ì£¼, ë°˜ì¥ë‹˜ ì „ë‹¬, ë§¤ê°ì—¬ë¶€, ê²½ë§¤/ê³µë§¤, ë‹´ë‹¹ê¸°ê´€, ë¬¼ê±´ì¢…ë¥˜, ì„¸ëŒ€ìˆ˜, ëŒ€ì§€ë©´ì , ì „ìš©ë©´ì (í•©ê³„), ëŒ€ì¶œì”ì•¡, ì´ìê¸ˆì•¡, ì—°ì²´ì´ììœ¨, ëŒ€ì¶œì›ê¸ˆ, ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„, ì±„ê¶Œìµœê³ ì•¡, ê°ì •ê°€, ì„ ìˆœìœ„ í•©ê³„, ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ

ì…ë ¥:
{batch_text}

ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ ```json ë¸”ë¡ìœ¼ë¡œ ì‹œì‘í•´ì„œ JSON ë¦¬ìŠ¤íŠ¸ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”.
"""

    with open(f"prompt_batch_{batch_idx+1}_with_headers.txt", "w", encoding="utf-8") as f:
        f.write(prompt)

    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            max_tokens=4096
        )
        msg = res.choices[0].message.content.strip()
        match = re.search(r"```json\s*(.*?)```", msg, re.DOTALL)
        json_str = match.group(1).strip() if match else msg
        return json.loads(json_str)
    except Exception as e:
        with open(f"gpt_error_batch_{batch_idx+1}_with_headers.txt", "w", encoding="utf-8") as f:
            f.write(msg if 'msg' in locals() else str(e))
        raise RuntimeError(f"GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Excel ë°ì´í„° ì¶”ì¶œ ë° ë¶„í• 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_batches_from_excel(file_path: str, batch_size: int = 10) -> List[List[str]]:
    xls = pd.ExcelFile(file_path)
    all_rows = []
    for sheet_name in xls.sheet_names:
        try:
            df = pd.read_excel(file_path, sheet_name=sheet_name, dtype=str, header=1).fillna("")
            for _, row in df.iterrows():
                text = f"[{sheet_name}] " + " | ".join([f"{col}:{row[col]}" for col in df.columns])
                all_rows.append(text)
        except Exception as e:
            log.warning(f"âš ï¸ ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    return [all_rows[i:i+batch_size] for i in range(0, len(all_rows), batch_size)]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Excel ê²°ê³¼ ì‚½ì… (ìˆ˜ì •ë¨)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def insert_batch_to_excel(batch_data: List[dict], output_path: str):
    wb = load_workbook(output_path)
    ws = wb["List"]
    col_order = [cell.value for cell in ws[2] if cell.value]
    start_col = 2
    start_row = find_last_row(ws) + 1
    
    # ê¸ˆì•¡ í•„ë“œ (ì´ììœ¨ ì œì™¸)
    money_fields = [
        "ê°ì •ê°€", "ëŒ€ì¶œì”ì•¡", "ì´ìê¸ˆì•¡", "ëŒ€ì¶œì›ê¸ˆ", "ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„",
        "ì±„ê¶Œìµœê³ ì•¡", "ì„ ìˆœìœ„ í•©ê³„", "ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ"
    ]
    
    # ì´ììœ¨ í•„ë“œ (ë³„ë„ ì²˜ë¦¬)
    interest_rate_fields = ["ì—°ì²´ì´ììœ¨"]
    
    # ìˆ«ì í•„ë“œ (ë©´ì , ì„¸ëŒ€ìˆ˜ ë“±)
    numeric_fields = ["ì„¸ëŒ€ìˆ˜", "ëŒ€ì§€ë©´ì ", "ì „ìš©ë©´ì (í•©ê³„)"]

    for item in batch_data:
        for col_idx, col_name in enumerate(col_order):
            raw = item.get(col_name, "")
            
            if col_name in money_fields:
                # ê¸ˆì•¡ í•„ë“œ: ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ float ë³€í™˜
                try:
                    value = float(re.sub(r"[^\d.]", "", str(raw))) if re.search(r"\d", str(raw)) else None
                except:
                    value = None
                    
            elif col_name in interest_rate_fields:
                # ì´ììœ¨ í•„ë“œ: ìˆ«ìë§Œ ì¶”ì¶œ í›„ 100ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                try:
                    # ëª¨ë“  ë¬¸ì ì œê±°í•˜ê³  ìˆ«ìë§Œ ì¶”ì¶œ
                    cleaned_num = re.sub(r"[^\d.]", "", str(raw))
                    if cleaned_num and re.search(r"\d", cleaned_num):
                        # 100ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì„œ ì •ìƒ ì´ììœ¨ë¡œ ë³€í™˜
                        value = float(cleaned_num) / 1
                        log.info(f"ğŸ” ì´ììœ¨ ì²˜ë¦¬: '{raw}' â†’ '{cleaned_num}' â†’ '{value}'")
                    else:
                        value = None
                except:
                    value = None
                    
            elif col_name in numeric_fields:
                # ì¼ë°˜ ìˆ«ì í•„ë“œ: ì‰¼í‘œ ì œê±°í•˜ê³  ìˆ«ì ë³€í™˜
                try:
                    cleaned = re.sub(r"[^\d.]", "", str(raw))
                    value = float(cleaned) if cleaned and re.search(r"\d", cleaned) else None
                except:
                    value = None
                    
            else:
                # í…ìŠ¤íŠ¸ í•„ë“œ: ê·¸ëŒ€ë¡œ ìœ ì§€
                value = raw
                
            ws.cell(row=start_row, column=start_col + col_idx, value=value)
        start_row += 1

    wb.save(output_path)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_file(upload_path: str, output_path: str):
    batches = extract_batches_from_excel(upload_path)
    detected_headers = []
    
    for idx, batch in enumerate(batches):
        try:
            batch_text = "\n\n".join(batch)
            if idx == 0:
                data, headers = call_gpt_first_batch(batch_text, idx)
                detected_headers = headers
                with open("detected_headers.json", "w", encoding="utf-8") as f:
                    json.dump(detected_headers, f, ensure_ascii=False, indent=2)
            else:
                data = call_gpt_with_headers(batch_text, idx, detected_headers)
            insert_batch_to_excel(data, output_path)
            log.info(f"âœ… ë°°ì¹˜ {idx+1}: {len(data)}í–‰ ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            log.error(f"âŒ ë°°ì¹˜ {idx+1} ì‹¤íŒ¨: {e}")
            continue

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/upload/")
async def upload_and_process(file: UploadFile = File(...)):
    upload_dir = Path("uploaded")
    upload_dir.mkdir(exist_ok=True)
    file_path = upload_dir / file.filename
    with open(file_path, "wb") as f:
        shutil.copyfileobj(file.file, f)
    log.info(f"ì—…ë¡œë“œë¨: {file_path}")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    out = Path(f"ì‘ì„±ë³¸_{Path(file.filename).stem}_{timestamp}.xlsx")
    shutil.copyfile(TEMPLATE_PATH, out)

    try:
        process_file(str(file_path), str(out))
    except Exception as e:
        log.error("ì²˜ë¦¬ ì‹¤íŒ¨", exc_info=e)
        raise HTTPException(status_code=500, detail=f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    return FileResponse(out)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œì»¬ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)
