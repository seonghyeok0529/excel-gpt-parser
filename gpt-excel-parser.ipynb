{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [3236]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:62925 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:62925 - \"GET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:62925 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 16:11:54,624 [INFO] ì—…ë¡œë“œë¨: uploaded\\2025 3á„á…¡ á„á…¢á„€á…¯á†«á„†á…¢á„€á…¡á†¨á„†á…§á†¼á„‰á…¦.xlsx\n",
      "2025-07-24 16:12:31,548 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-24 16:13:10,408 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.11323' â†’ '0.11323' â†’ '0.11323'\n",
      "2025-07-24 16:13:10,411 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0957' â†’ '0.0957' â†’ '0.0957'\n",
      "2025-07-24 16:13:10,412 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0831' â†’ '0.0831' â†’ '0.0831'\n",
      "2025-07-24 16:13:10,413 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0937' â†’ '0.0937' â†’ '0.0937'\n",
      "2025-07-24 16:13:10,415 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0903' â†’ '0.0903' â†’ '0.0903'\n",
      "2025-07-24 16:13:10,416 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0808' â†’ '0.0808' â†’ '0.0808'\n",
      "2025-07-24 16:13:10,417 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0878' â†’ '0.0878' â†’ '0.0878'\n",
      "2025-07-24 16:13:10,418 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.09114' â†’ '0.09114' â†’ '0.09114'\n",
      "2025-07-24 16:13:41,719 [INFO] âœ… ë°°ì¹˜ 1: 8í–‰ ì¶”ê°€ ì™„ë£Œ\n",
      "2025-07-24 16:14:14,527 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-24 16:15:00,940 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.08499' â†’ '0.08499' â†’ '0.08499'\n",
      "2025-07-24 16:15:00,942 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.09563' â†’ '0.09563' â†’ '0.09563'\n",
      "2025-07-24 16:15:00,944 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.1021' â†’ '0.1021' â†’ '0.1021'\n",
      "2025-07-24 16:15:00,945 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.08923' â†’ '0.08923' â†’ '0.08923'\n",
      "2025-07-24 16:15:00,946 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0878' â†’ '0.0878' â†’ '0.0878'\n",
      "2025-07-24 16:15:00,947 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0879' â†’ '0.0879' â†’ '0.0879'\n",
      "2025-07-24 16:15:00,948 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.08773' â†’ '0.08773' â†’ '0.08773'\n",
      "2025-07-24 16:15:00,949 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.09533' â†’ '0.09533' â†’ '0.09533'\n",
      "2025-07-24 16:15:00,950 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0908' â†’ '0.0908' â†’ '0.0908'\n",
      "2025-07-24 16:15:35,785 [INFO] âœ… ë°°ì¹˜ 2: 9í–‰ ì¶”ê°€ ì™„ë£Œ\n",
      "2025-07-24 16:16:15,848 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-24 16:16:57,416 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0878' â†’ '0.0878' â†’ '0.0878'\n",
      "2025-07-24 16:16:57,418 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0967' â†’ '0.0967' â†’ '0.0967'\n",
      "2025-07-24 16:16:57,419 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0848' â†’ '0.0848' â†’ '0.0848'\n",
      "2025-07-24 16:16:57,421 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0848' â†’ '0.0848' â†’ '0.0848'\n",
      "2025-07-24 16:16:57,422 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0871' â†’ '0.0871' â†’ '0.0871'\n",
      "2025-07-24 16:16:57,423 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0856' â†’ '0.0856' â†’ '0.0856'\n",
      "2025-07-24 16:16:57,424 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0921' â†’ '0.0921' â†’ '0.0921'\n",
      "2025-07-24 16:16:57,425 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.0946' â†’ '0.0946' â†’ '0.0946'\n",
      "2025-07-24 16:16:57,426 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.11513' â†’ '0.11513' â†’ '0.11513'\n",
      "2025-07-24 16:16:57,427 [INFO] ğŸ” ì´ììœ¨ ì²˜ë¦¬: '0.09883' â†’ '0.09883' â†’ '0.09883'\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, json, logging, re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import FileResponse\n",
    "from openpyxl import load_workbook\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio, uvicorn\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# í™˜ê²½ ì„¤ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TEMPLATE_PATH = Path(os.getenv(\"TEMPLATE_PATH\", r\"C:\\Users\\che98\\Downloads\\ìˆ˜ìµë¥ í‘œ(Brief Version)_1.0_í…œí”Œë¦¿.xlsx\"))\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FastAPI ì•± ë° ë¡œê¹… ì„¤ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "app = FastAPI()\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "log = logging.getLogger(__name__)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ìœ í‹¸ í•¨ìˆ˜\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def find_last_row(ws):\n",
    "    for row in reversed(range(1, ws.max_row + 1)):\n",
    "        if any(cell.value for cell in ws[row]):\n",
    "            return row\n",
    "    return 2\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# GPT í˜¸ì¶œ - ì²« ë°°ì¹˜\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def call_gpt_first_batch(batch_text: str, batch_idx: int) -> tuple[List[dict], List[str]]:\n",
    "    prompt = f\"\"\"\n",
    "ë‹¤ìŒì€ ë¶€ì‹¤ì±„ê¶Œ ìš”ì•½ í…ìŠ¤íŠ¸ ëª©ë¡ì…ë‹ˆë‹¤. \n",
    "\n",
    "**1ë‹¨ê³„: í—¤ë” ì •ë³´ ì¶”ì¶œ**\n",
    "ë¨¼ì € ì´ ë°ì´í„°ì—ì„œ ì»¬ëŸ¼ í—¤ë”ë‚˜ í•„ë“œëª…ì„ ì°¾ì•„ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "**2ë‹¨ê³„: ë°ì´í„° ì •ë¦¬**\n",
    "ê° í•­ëª©ì„ ì•„ë˜ í•­ëª©ë“¤ì— ë§ê²Œ JSONìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "- ìˆ«ìëŠ” ì‰¼í‘œ(,) ì—†ì´ ìˆ«ìí˜•ìœ¼ë¡œ, ì†Œìˆ˜ì ì€ ìœ ì§€í•´ì£¼ì„¸ìš”\n",
    "- **ì´ììœ¨ì€ %ë¥¼ ì œê±°í•˜ê³  ì†Œìˆ˜ì  í˜•íƒœë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”** (ì˜ˆ: 11.323%ì´ë©´ 0.11323ìœ¼ë¡œ)\n",
    "- ê°™ì€ í•„ë“œê°€ í•œ ì¤„ì— ì—¬ëŸ¬ ë²ˆ ë“±ì¥í•˜ë©´ í•©ì‚°\n",
    "- í•­ëª©ì´ ì¤‘ë³µë˜ë©´ ì ì ˆíˆ êµ¬ë¶„í•´ì„œ í•„ë“œì— ë°°ì •\n",
    "- íŠ¹íˆ, ê°€ì§€ê¸‰ê¸ˆì€ \"ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ\"ìœ¼ë¡œ, ë¯¸ìˆ˜ì´ìëŠ” \"ì´ìê¸ˆì•¡\" ë˜ëŠ” \"ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„\"ì™€ êµ¬ë¶„\n",
    "- ì±„ê¶Œìµœê³ ì•¡ì€ ë³´í†µ ê°€ì¥ í° ê¸ˆì•¡ì´ë©° ê·¸ í•­ëª© ì „ìš©ìœ¼ë¡œ\n",
    "\n",
    "í•„ë“œ: ì£¼ì†Œ, í˜¸ìˆ˜, ê²€í† ì¼, ì°¨ì£¼, ë°˜ì¥ë‹˜ ì „ë‹¬, ë§¤ê°ì—¬ë¶€, ê²½ë§¤/ê³µë§¤, ë‹´ë‹¹ê¸°ê´€, ë¬¼ê±´ì¢…ë¥˜, ì„¸ëŒ€ìˆ˜, ëŒ€ì§€ë©´ì , ì „ìš©ë©´ì (í•©ê³„), ëŒ€ì¶œì”ì•¡, ì´ìê¸ˆì•¡, ì—°ì²´ì´ììœ¨, ëŒ€ì¶œì›ê¸ˆ, ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„, ì±„ê¶Œìµœê³ ì•¡, ê°ì •ê°€, ì„ ìˆœìœ„ í•©ê³„, ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ\n",
    "\n",
    "ì…ë ¥:\n",
    "{batch_text}\n",
    "\n",
    "ì‘ë‹µ í˜•ì‹:\n",
    "```json\n",
    "{{\n",
    "  \"headers\": [\"ê°ì§€ëœ í—¤ë”1\", \"ê°ì§€ëœ í—¤ë”2\", ...],\n",
    "  \"data\": [\n",
    "    {{\"ì£¼ì†Œ\": \"ê°’\", \"í˜¸ìˆ˜\": \"ê°’\", ...}},\n",
    "    {{\"ì£¼ì†Œ\": \"ê°’\", \"í˜¸ìˆ˜\": \"ê°’\", ...}}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\"\"\"\n",
    "    with open(f\"prompt_batch_{batch_idx+1}_first.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(prompt)\n",
    "\n",
    "    try:\n",
    "        res = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        msg = res.choices[0].message.content.strip()\n",
    "        match = re.search(r\"```json\\s*(.*?)```\", msg, re.DOTALL)\n",
    "        json_str = match.group(1).strip() if match else msg\n",
    "        result = json.loads(json_str)\n",
    "        return result.get(\"data\", []), result.get(\"headers\", [])\n",
    "    except Exception as e:\n",
    "        with open(f\"gpt_error_batch_{batch_idx+1}_first.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(msg if 'msg' in locals() else str(e))\n",
    "        raise RuntimeError(f\"GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# GPT í˜¸ì¶œ - ì´í›„ ë°°ì¹˜\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def call_gpt_with_headers(batch_text: str, batch_idx: int, headers: List[str]) -> List[dict]:\n",
    "    headers_str = \", \".join(headers) if headers else \"í—¤ë” ì •ë³´ ì—†ìŒ\"\n",
    "    prompt = f\"\"\"\n",
    "ë‹¤ìŒì€ ë¶€ì‹¤ì±„ê¶Œ ìš”ì•½ í…ìŠ¤íŠ¸ ëª©ë¡ì…ë‹ˆë‹¤. \n",
    "\n",
    "**ì°¸ê³  í—¤ë” ì •ë³´:**\n",
    "ì´ì „ ë°°ì¹˜ì—ì„œ ê°ì§€ëœ í—¤ë”: {headers_str}\n",
    "\n",
    "ì´ í—¤ë” ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ê° í•­ëª©ì„ ì•„ë˜ í•­ëª©ë“¤ì— ë§ê²Œ JSONìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "- ìˆ«ìëŠ” ì‰¼í‘œ(,) ì—†ì´ ìˆ«ìí˜•ìœ¼ë¡œ, ì†Œìˆ˜ì ì€ ìœ ì§€í•´ì£¼ì„¸ìš”\n",
    "- **ì´ììœ¨ì€ %ë¥¼ ì œê±°í•˜ê³  ì†Œìˆ˜ì  í˜•íƒœë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”** (ì˜ˆ: 11.323%ì´ë©´ 0.11323ìœ¼ë¡œ)\n",
    "- ê°™ì€ í•„ë“œê°€ í•œ ì¤„ì— ì—¬ëŸ¬ ë²ˆ ë“±ì¥í•˜ë©´ í•©ì‚°\n",
    "- í•­ëª©ì´ ì¤‘ë³µë˜ë©´ ì ì ˆíˆ êµ¬ë¶„í•´ì„œ í•„ë“œì— ë°°ì •\n",
    "- íŠ¹íˆ, ê°€ì§€ê¸‰ê¸ˆì€ \"ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ\"ìœ¼ë¡œ, ë¯¸ìˆ˜ì´ìëŠ” \"ì´ìê¸ˆì•¡\" ë˜ëŠ” \"ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„\"ì™€ êµ¬ë¶„\n",
    "- ì±„ê¶Œìµœê³ ì•¡ì€ ë³´í†µ ê°€ì¥ í° ê¸ˆì•¡ì´ë©° ê·¸ í•­ëª© ì „ìš©ìœ¼ë¡œ\n",
    "- ì¶œë ¥ì€ ë°˜ë“œì‹œ ```json ìœ¼ë¡œ ê°ì‹¸ì§„ JSON ë¦¬ìŠ¤íŠ¸ë¡œ\n",
    "\n",
    "í•„ë“œ: ì£¼ì†Œ, í˜¸ìˆ˜, ê²€í† ì¼, ì°¨ì£¼, ë°˜ì¥ë‹˜ ì „ë‹¬, ë§¤ê°ì—¬ë¶€, ê²½ë§¤/ê³µë§¤, ë‹´ë‹¹ê¸°ê´€, ë¬¼ê±´ì¢…ë¥˜, ì„¸ëŒ€ìˆ˜, ëŒ€ì§€ë©´ì , ì „ìš©ë©´ì (í•©ê³„), ëŒ€ì¶œì”ì•¡, ì´ìê¸ˆì•¡, ì—°ì²´ì´ììœ¨, ëŒ€ì¶œì›ê¸ˆ, ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„, ì±„ê¶Œìµœê³ ì•¡, ê°ì •ê°€, ì„ ìˆœìœ„ í•©ê³„, ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ\n",
    "\n",
    "ì…ë ¥:\n",
    "{batch_text}\n",
    "\n",
    "ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ ```json ë¸”ë¡ìœ¼ë¡œ ì‹œì‘í•´ì„œ JSON ë¦¬ìŠ¤íŠ¸ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "    with open(f\"prompt_batch_{batch_idx+1}_with_headers.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(prompt)\n",
    "\n",
    "    try:\n",
    "        res = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        msg = res.choices[0].message.content.strip()\n",
    "        match = re.search(r\"```json\\s*(.*?)```\", msg, re.DOTALL)\n",
    "        json_str = match.group(1).strip() if match else msg\n",
    "        return json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        with open(f\"gpt_error_batch_{batch_idx+1}_with_headers.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(msg if 'msg' in locals() else str(e))\n",
    "        raise RuntimeError(f\"GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Excel ë°ì´í„° ì¶”ì¶œ ë° ë¶„í• \n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def extract_batches_from_excel(file_path: str, batch_size: int = 10) -> List[List[str]]:\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    all_rows = []\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name, dtype=str, header=1).fillna(\"\")\n",
    "            for _, row in df.iterrows():\n",
    "                text = f\"[{sheet_name}] \" + \" | \".join([f\"{col}:{row[col]}\" for col in df.columns])\n",
    "                all_rows.append(text)\n",
    "        except Exception as e:\n",
    "            log.warning(f\"âš ï¸ ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "    return [all_rows[i:i+batch_size] for i in range(0, len(all_rows), batch_size)]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Excel ê²°ê³¼ ì‚½ì… (ìˆ˜ì •ë¨)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def insert_batch_to_excel(batch_data: List[dict], output_path: str):\n",
    "    wb = load_workbook(output_path)\n",
    "    ws = wb[\"List\"]\n",
    "    col_order = [cell.value for cell in ws[2] if cell.value]\n",
    "    start_col = 2\n",
    "    start_row = find_last_row(ws) + 1\n",
    "    \n",
    "    # ê¸ˆì•¡ í•„ë“œ (ì´ììœ¨ ì œì™¸)\n",
    "    money_fields = [\n",
    "        \"ê°ì •ê°€\", \"ëŒ€ì¶œì”ì•¡\", \"ì´ìê¸ˆì•¡\", \"ëŒ€ì¶œì›ê¸ˆ\", \"ì±„ê¶Œ ê¶Œë¦¬ í•©ê³„\",\n",
    "        \"ì±„ê¶Œìµœê³ ì•¡\", \"ì„ ìˆœìœ„ í•©ê³„\", \"ì—¬ì‹ ì„± ê°€ì§€ê¸‰ê¸ˆ\"\n",
    "    ]\n",
    "    \n",
    "    # ì´ììœ¨ í•„ë“œ (ë³„ë„ ì²˜ë¦¬)\n",
    "    interest_rate_fields = [\"ì—°ì²´ì´ììœ¨\"]\n",
    "    \n",
    "    # ìˆ«ì í•„ë“œ (ë©´ì , ì„¸ëŒ€ìˆ˜ ë“±)\n",
    "    numeric_fields = [\"ì„¸ëŒ€ìˆ˜\", \"ëŒ€ì§€ë©´ì \", \"ì „ìš©ë©´ì (í•©ê³„)\"]\n",
    "\n",
    "    for item in batch_data:\n",
    "        for col_idx, col_name in enumerate(col_order):\n",
    "            raw = item.get(col_name, \"\")\n",
    "            \n",
    "            if col_name in money_fields:\n",
    "                # ê¸ˆì•¡ í•„ë“œ: ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ float ë³€í™˜\n",
    "                try:\n",
    "                    value = float(re.sub(r\"[^\\d.]\", \"\", str(raw))) if re.search(r\"\\d\", str(raw)) else None\n",
    "                except:\n",
    "                    value = None\n",
    "                    \n",
    "            elif col_name in interest_rate_fields:\n",
    "                # ì´ììœ¨ í•„ë“œ: ìˆ«ìë§Œ ì¶”ì¶œ í›„ 100ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "                try:\n",
    "                    # ëª¨ë“  ë¬¸ì ì œê±°í•˜ê³  ìˆ«ìë§Œ ì¶”ì¶œ\n",
    "                    cleaned_num = re.sub(r\"[^\\d.]\", \"\", str(raw))\n",
    "                    if cleaned_num and re.search(r\"\\d\", cleaned_num):\n",
    "                        # 100ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì„œ ì •ìƒ ì´ììœ¨ë¡œ ë³€í™˜\n",
    "                        value = float(cleaned_num) / 1\n",
    "                        log.info(f\"ğŸ” ì´ììœ¨ ì²˜ë¦¬: '{raw}' â†’ '{cleaned_num}' â†’ '{value}'\")\n",
    "                    else:\n",
    "                        value = None\n",
    "                except:\n",
    "                    value = None\n",
    "                    \n",
    "            elif col_name in numeric_fields:\n",
    "                # ì¼ë°˜ ìˆ«ì í•„ë“œ: ì‰¼í‘œ ì œê±°í•˜ê³  ìˆ«ì ë³€í™˜\n",
    "                try:\n",
    "                    cleaned = re.sub(r\"[^\\d.]\", \"\", str(raw))\n",
    "                    value = float(cleaned) if cleaned and re.search(r\"\\d\", cleaned) else None\n",
    "                except:\n",
    "                    value = None\n",
    "                    \n",
    "            else:\n",
    "                # í…ìŠ¤íŠ¸ í•„ë“œ: ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "                value = raw\n",
    "                \n",
    "            ws.cell(row=start_row, column=start_col + col_idx, value=value)\n",
    "        start_row += 1\n",
    "\n",
    "    wb.save(output_path)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def process_file(upload_path: str, output_path: str):\n",
    "    batches = extract_batches_from_excel(upload_path)\n",
    "    detected_headers = []\n",
    "    \n",
    "    for idx, batch in enumerate(batches):\n",
    "        try:\n",
    "            batch_text = \"\\n\\n\".join(batch)\n",
    "            if idx == 0:\n",
    "                data, headers = call_gpt_first_batch(batch_text, idx)\n",
    "                detected_headers = headers\n",
    "                with open(\"detected_headers.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(detected_headers, f, ensure_ascii=False, indent=2)\n",
    "            else:\n",
    "                data = call_gpt_with_headers(batch_text, idx, detected_headers)\n",
    "            insert_batch_to_excel(data, output_path)\n",
    "            log.info(f\"âœ… ë°°ì¹˜ {idx+1}: {len(data)}í–‰ ì¶”ê°€ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            log.error(f\"âŒ ë°°ì¹˜ {idx+1} ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "@app.post(\"/upload/\")\n",
    "async def upload_and_process(file: UploadFile = File(...)):\n",
    "    upload_dir = Path(\"uploaded\")\n",
    "    upload_dir.mkdir(exist_ok=True)\n",
    "    file_path = upload_dir / file.filename\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        shutil.copyfileobj(file.file, f)\n",
    "    log.info(f\"ì—…ë¡œë“œë¨: {file_path}\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out = Path(f\"ì‘ì„±ë³¸_{Path(file.filename).stem}_{timestamp}.xlsx\")\n",
    "    shutil.copyfile(TEMPLATE_PATH, out)\n",
    "\n",
    "    try:\n",
    "        process_file(str(file_path), str(out))\n",
    "    except Exception as e:\n",
    "        log.error(\"ì²˜ë¦¬ ì‹¤íŒ¨\", exc_info=e)\n",
    "        raise HTTPException(status_code=500, detail=f\"ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    return FileResponse(out)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ë¡œì»¬ ì‹¤í–‰\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
